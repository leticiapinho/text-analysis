{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\letic\\miniconda3\\envs\\text_analysis\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Bibliotecas utilizadas no projeto\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos dados que serão analisados\n",
    "\n",
    "df = pd.read_excel(r\"data\\dados_funks.xlsx\", usecols=['Nº da ficha:', 'Título da música:', 'Canal:',\n",
    "       'Nº de visualizações:', 'Nº de inscritos:', 'Data de publicação', 'MC:','DJ:', 'Duração:', \n",
    "       'Estado:', 'Cidade:','Transcrição:'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nº da ficha:</th>\n",
       "      <th>Título da música:</th>\n",
       "      <th>Canal:</th>\n",
       "      <th>Nº de visualizações:</th>\n",
       "      <th>Nº de inscritos:</th>\n",
       "      <th>Data de publicação</th>\n",
       "      <th>MC:</th>\n",
       "      <th>DJ:</th>\n",
       "      <th>Duração:</th>\n",
       "      <th>Estado:</th>\n",
       "      <th>Cidade:</th>\n",
       "      <th>Transcrição:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pela 1 vez juntos :: MC`S. Menor do Chapa e Ma...</td>\n",
       "      <td>Roda de Funk Original</td>\n",
       "      <td>240937.0</td>\n",
       "      <td>695998.0</td>\n",
       "      <td>2014-04-28 00:00:00</td>\n",
       "      <td>Menor do Chapa e Mazinho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>1.\\tMC Novinha: - Nós somos PCM porque temos d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mc sadrak Papo reto bonde dos 40 pedrinhas</td>\n",
       "      <td>lucas Sousa</td>\n",
       "      <td>95042.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>2014-08-01 00:00:00</td>\n",
       "      <td>Sadrak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02:50:00</td>\n",
       "      <td>Maranhão</td>\n",
       "      <td>São Luís</td>\n",
       "      <td>Se for falar que é cv no jura nao pode mais\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bonde dos 40 :::: Mc Sadrak ((Sonho de Liberda...</td>\n",
       "      <td>Conexão  B.40</td>\n",
       "      <td>3938.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>2016-05-26 00:00:00</td>\n",
       "      <td>Sadrak</td>\n",
       "      <td>não informado</td>\n",
       "      <td>03:39:00</td>\n",
       "      <td>Maranhão</td>\n",
       "      <td>São Luís</td>\n",
       "      <td>Só soldado preparado no Jacaré\\n\\nChamada jorn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nº da ficha:                                  Título da música:  \\\n",
       "0             1  Pela 1 vez juntos :: MC`S. Menor do Chapa e Ma...   \n",
       "1             2         Mc sadrak Papo reto bonde dos 40 pedrinhas   \n",
       "2             3  Bonde dos 40 :::: Mc Sadrak ((Sonho de Liberda...   \n",
       "\n",
       "                  Canal:  Nº de visualizações:  Nº de inscritos:  \\\n",
       "0  Roda de Funk Original              240937.0          695998.0   \n",
       "1            lucas Sousa               95042.0             892.0   \n",
       "2          Conexão  B.40                3938.0            3400.0   \n",
       "\n",
       "    Data de publicação                       MC:            DJ:  Duração:  \\\n",
       "0  2014-04-28 00:00:00  Menor do Chapa e Mazinho            NaN  11:01:00   \n",
       "1  2014-08-01 00:00:00                    Sadrak            NaN  02:50:00   \n",
       "2  2016-05-26 00:00:00                    Sadrak  não informado  03:39:00   \n",
       "\n",
       "          Estado:         Cidade:  \\\n",
       "0  Rio de Janeiro  Rio de Janeiro   \n",
       "1        Maranhão        São Luís   \n",
       "2        Maranhão        São Luís   \n",
       "\n",
       "                                        Transcrição:  \n",
       "0  1.\\tMC Novinha: - Nós somos PCM porque temos d...  \n",
       "1  Se for falar que é cv no jura nao pode mais\\n\\...  \n",
       "2  Só soldado preparado no Jacaré\\n\\nChamada jorn...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texto'] = df['Transcrição:']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminação de tabulação escape lines\n",
    "df['texto'].replace(r'\\r+|\\n+|\\t+',' ', regex=True, inplace=True)\n",
    "\n",
    "# Conversão do texto para letras minúsculas\n",
    "df['texto'] = df['texto'].str.lower()\n",
    "\n",
    "# Eliminação de caracteres especiais\n",
    "df['texto'] = df['texto'].str.replace('\\W', ' ', regex=True)\n",
    "\n",
    "# Eliminação dos números\n",
    "df['texto'] = df['texto'].str.replace('\\d+', '', regex=True)\n",
    "\n",
    "# Eliminação de espaços vazios\n",
    "df['texto'] = df['texto'].str.replace('  ',' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcrição:</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.\\tMC Novinha: - Nós somos PCM porque temos d...</td>\n",
       "      <td>mc novinha  nós somos pcm porque temos dispos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Se for falar que é cv no jura nao pode mais\\n\\...</td>\n",
       "      <td>se for falar que é cv no jura nao pode mais  v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Só soldado preparado no Jacaré\\n\\nChamada jorn...</td>\n",
       "      <td>só soldado preparado no jacaré chamada jornalí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.\\tMas sai da frente aí seus verme\\n2.\\tQue o...</td>\n",
       "      <td>mas sai da frente aí seus verme  que o bonde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embratel é Primeiro Comando\\n1.\\tO de cinza br...</td>\n",
       "      <td>embratel é primeiro comando  o de cinza brotou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Transcrição:  \\\n",
       "0  1.\\tMC Novinha: - Nós somos PCM porque temos d...   \n",
       "1  Se for falar que é cv no jura nao pode mais\\n\\...   \n",
       "2  Só soldado preparado no Jacaré\\n\\nChamada jorn...   \n",
       "3  1.\\tMas sai da frente aí seus verme\\n2.\\tQue o...   \n",
       "4  Embratel é Primeiro Comando\\n1.\\tO de cinza br...   \n",
       "\n",
       "                                               texto  \n",
       "0   mc novinha  nós somos pcm porque temos dispos...  \n",
       "1  se for falar que é cv no jura nao pode mais  v...  \n",
       "2  só soldado preparado no jacaré chamada jornalí...  \n",
       "3   mas sai da frente aí seus verme  que o bonde ...  \n",
       "4  embratel é primeiro comando  o de cinza brotou...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['Transcrição:', 'texto']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização \n",
    "regexp = RegexpTokenizer('\\w+')\n",
    "df['tokens']=df['texto'].apply(regexp.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [mc, novinha, nós, somos, pcm, porque, temos, ...\n",
       "1    [se, for, falar, que, é, cv, no, jura, nao, po...\n",
       "2    [só, soldado, preparado, no, jacaré, chamada, ...\n",
       "3    [mas, sai, da, frente, aí, seus, verme, que, o...\n",
       "4    [embratel, é, primeiro, comando, o, de, cinza,...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos']\n"
     ]
    }
   ],
   "source": [
    "# Verificação das stopwords listadas para o idioma português\n",
    "print(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminação das stopwords\n",
    "port_stopwords = stopwords.words('portuguese')\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [item for item in x if item not in port_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcrição:</th>\n",
       "      <th>texto</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.\\tMC Novinha: - Nós somos PCM porque temos d...</td>\n",
       "      <td>mc novinha  nós somos pcm porque temos dispos...</td>\n",
       "      <td>[mc, novinha, pcm, porque, disposição, pcm, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Se for falar que é cv no jura nao pode mais\\n\\...</td>\n",
       "      <td>se for falar que é cv no jura nao pode mais  v...</td>\n",
       "      <td>[falar, cv, jura, nao, pode, vou, dá, papo, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Só soldado preparado no Jacaré\\n\\nChamada jorn...</td>\n",
       "      <td>só soldado preparado no jacaré chamada jornalí...</td>\n",
       "      <td>[soldado, preparado, jacaré, chamada, jornalís...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.\\tMas sai da frente aí seus verme\\n2.\\tQue o...</td>\n",
       "      <td>mas sai da frente aí seus verme  que o bonde ...</td>\n",
       "      <td>[sai, frente, aí, verme, bonde, vai, passar, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embratel é Primeiro Comando\\n1.\\tO de cinza br...</td>\n",
       "      <td>embratel é primeiro comando  o de cinza brotou...</td>\n",
       "      <td>[embratel, primeiro, comando, cinza, brotou, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Transcrição:  \\\n",
       "0  1.\\tMC Novinha: - Nós somos PCM porque temos d...   \n",
       "1  Se for falar que é cv no jura nao pode mais\\n\\...   \n",
       "2  Só soldado preparado no Jacaré\\n\\nChamada jorn...   \n",
       "3  1.\\tMas sai da frente aí seus verme\\n2.\\tQue o...   \n",
       "4  Embratel é Primeiro Comando\\n1.\\tO de cinza br...   \n",
       "\n",
       "                                               texto  \\\n",
       "0   mc novinha  nós somos pcm porque temos dispos...   \n",
       "1  se for falar que é cv no jura nao pode mais  v...   \n",
       "2  só soldado preparado no jacaré chamada jornalí...   \n",
       "3   mas sai da frente aí seus verme  que o bonde ...   \n",
       "4  embratel é primeiro comando  o de cinza brotou...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [mc, novinha, pcm, porque, disposição, pcm, po...  \n",
       "1  [falar, cv, jura, nao, pode, vou, dá, papo, ma...  \n",
       "2  [soldado, preparado, jacaré, chamada, jornalís...  \n",
       "3  [sai, frente, aí, verme, bonde, vai, passar, a...  \n",
       "4  [embratel, primeiro, comando, cinza, brotou, l...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['Transcrição:', 'texto','tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências para adaptar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns a regular Python list\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Add a list of words\n",
    "english_stopwords.extend(['food', 'meal', 'eat'])\n",
    "\n",
    "# Add a single word\n",
    "english_stopwords.append('plate')\n",
    "\n",
    "# Remove a single word\n",
    "english_stopwords.remove('not')\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "# Extend the list with your own custom stopwords\n",
    "my_stopwords = ['https']\n",
    "stopwords.extend(my_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import Counter\n",
    "#wd = pd.DataFrame(Counter(df['Transcrição:'].split()).most_common(200), columns=['Transcrição:'])\n",
    "#df.apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Choose a character\n",
    "df = df[df['name']  == \"cersei\"]\n",
    "# Make all words lowercase and add them to an array\n",
    "words = ''\n",
    "for i in df.line.values:\n",
    "    words += '{} '.format(i.lower())\n",
    "# Create a pandas dataframe with the word and its frequency\n",
    "wd = pd.DataFrame(Counter(words.split()).most_common(200), columns=['word', 'frequency'])\n",
    "# Convert the dataframe to a dictionary\n",
    "data = dict(zip(wd['word'].tolist(), wd['frequency'].tolist()))\n",
    "\n",
    "wc = WordCloud(background_color='white',\n",
    "               stopwords=STOPWORDS,\n",
    "               max_words=200).generate_from_frequencies(data)\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squarify\n",
    "df = df.groupby(['name','sex', 'color'])['words'].sum().reset_index()\n",
    "\n",
    "x1=pd.Series(df['name'])\n",
    "x2=pd.Series(df['words'])\n",
    "x3=pd.Series(df['color'])\n",
    "x2=x2.tolist()\n",
    "x1=x1.tolist()\n",
    "x3=x3.tolist()\n",
    "\n",
    "squarify.plot(\n",
    "sizes=x2, \n",
    "label=x1, \n",
    "color =x3,\n",
    "alpha=.7,\n",
    "bar_kwargs=dict(linewidth=1, edgecolor=\"#222222\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('text_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3ee68468e2c72b23882e9e8334ecc1578d148d22499900a21258691cdd6df6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
